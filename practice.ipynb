{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(a):\n",
    "    y = np.exp(a) / np.sum(np.exp(a))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "print(sum(softmax(a)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "[[-7 -6 -5 -4]\n",
      " [-3 -2 -1  0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4],\n",
    "             [5,6,7,8]])\n",
    "print(np.max(a))\n",
    "print(a - np.max(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim: 1\n",
      "[0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "\n",
      "ndim:2\n",
      "[[0.0320586  0.08714432 0.23688282 0.64391426]\n",
      " [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      " [0.01521943 0.0413707  0.11245721 0.83095266]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(a):\n",
    "    # a: (b, n)\n",
    "    if a.ndim == 2:\n",
    "        # a.max(axis=1, keepdims=True): (b, 1)\n",
    "        a = a - a.max(axis=1, keepdims=True)\n",
    "        a = np.exp(a)\n",
    "        # np.sum(a, axis=1, keepdims=True): (b, 1)\n",
    "        y = a / np.sum(a, axis=1, keepdims=True)\n",
    "    elif a.ndim == 1:\n",
    "        # 이전 구현과 동일\n",
    "        a = a - np.max(a)\n",
    "        y = np.exp(a) / np.sum(np.exp(a))\n",
    "    return y\n",
    "\n",
    "a_1 = np.array([1,2,3,4])\n",
    "a_2 = np.array([[1,2,3,4],\n",
    "                [5,6,7,8],\n",
    "                [9,10,11,13]])\n",
    "\n",
    "print(\"ndim: 1\")\n",
    "print(softmax(a_1))\n",
    "\n",
    "print(\"\\nndim:2\")\n",
    "print(softmax(a_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndim: 1\n",
      "[0.0320586  0.08714432 0.23688282 0.64391426]\n",
      "\n",
      "ndim:2\n",
      "[[0.0320586  0.08714432 0.23688282 0.64391426]\n",
      " [0.0320586  0.08714432 0.23688282 0.64391426]\n",
      " [0.01521943 0.0413707  0.11245721 0.83095266]]\n"
     ]
    }
   ],
   "source": [
    "def softmax_2(a):\n",
    "    # a: (b, n)\n",
    "    if a.ndim == 2:\n",
    "        a = a.T # (a.T): (n, b)\n",
    "        a = a - a.max(axis=0) # a.max(axis=0): (b,)\n",
    "        y = np.exp(a) / np.sum(np.exp(a), axis=0) # np.sum(np.exp(a), axis=0): (b,)\n",
    "        return y.T # (n, b) -> (b, n)\n",
    "    elif a.ndim == 1:\n",
    "        # 이전 구현과 동일\n",
    "        a = a - np.max(a)\n",
    "        y = np.exp(a) / np.sum(np.exp(a))\n",
    "    return y\n",
    "\n",
    "a_1 = np.array([1,2,3,4])\n",
    "a_2 = np.array([[1,2,3,4],\n",
    "                [5,6,7,8],\n",
    "                [9,10,11,13]])\n",
    "\n",
    "print(\"ndim: 1\")\n",
    "print(softmax_2(a_1))\n",
    "\n",
    "print(\"\\nndim:2\")\n",
    "print(softmax_2(a_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0320586  0.0320586  0.01521943]\n",
      " [0.08714432 0.08714432 0.0413707 ]\n",
      " [0.23688282 0.23688282 0.11245721]\n",
      " [0.64391426 0.64391426 0.83095266]]\n"
     ]
    }
   ],
   "source": [
    "k = a_2.T - a_2.T.max(axis=0)\n",
    "print(np.exp(k) / np.sum(np.exp(k), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __init__(self):\n",
    "        self.params, grads = [], []\n",
    "        self.out = None\n",
    "    \n",
    "    def forward(self, a):\n",
    "        out = softmax(a)\n",
    "        self.out = out\n",
    "        return self.out\n",
    "    \n",
    "    def backward(self, dout):\n",
    "        # dout = (∂L/∂y)\n",
    "        dx = self.out * dout\n",
    "        sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "        dx -= self.out * sumdx\n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1: # 1차원인 경우 배치 처리할 때와 동일하게 2차원으로 맞춰주기\n",
    "        y = y.reshpae(1, y.size)\n",
    "        t = t.reshape(1, t.size)\n",
    "    \n",
    "    if t.size == y.size: # 원 핫 벡터를 레이블 인덱스로 변환하기\n",
    "        t = t.argmax(axis=1)\n",
    "    \n",
    "    batch_size = y.shape[0] # 샘플 개수로 나눠 평균 취하기\n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftmaxWithLoss:\n",
    "    def __init__(self):\n",
    "        self.params, grads = [], []\n",
    "        self.y = None # 소프트맥스 출력값\n",
    "        self.t = None # 정답 레이블 인덱스\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        self.t = t\n",
    "        self.y = softmax(x)\n",
    "\n",
    "        if self.t.size == self.y.size: # 원핫 벡터인 경우 레이블 인덱스로 변환\n",
    "            self.t = self.t.argmax(axis=1)\n",
    "        \n",
    "        loss = cross_entropy_error(self.y, self.t)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout=1):\n",
    "        batch_size = self.t.shape[0] # 샘플 개수 체크\n",
    "\n",
    "        dx = self.y.copy() # 입력을 복사\n",
    "        dx[np.arange(batch_size), self.t] -= 1 # 정답 인덱스에 접근하여 -1\n",
    "        dx *= dout # 이전 계층 미분 계수 곱해주기\n",
    "        dx = dx / batch_size # 샘플 개수로 나눠 평균 취하기\n",
    "\n",
    "        return dx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 2\n",
      "t: [0 1]\n",
      "y[np.arange(batch_size), t]: [0.1 0.3]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([[0.1, 0.2, 0.7],\n",
    "              [0.2, 0.3, 0.5]])\n",
    "\n",
    "batch_size = y.shape[0]\n",
    "print(f\"batch size: {batch_size}\") # 2\n",
    "\n",
    "t = np.array([[1, 0, 0],\n",
    "              [0, 1, 0]])\n",
    "t = t.argmax(axis=1)\n",
    "print(f\"t: {t}\") # [0 1]\n",
    "\n",
    "print(f\"y[np.arange(batch_size), t]: {y[np.arange(batch_size), t]}\") # [0.1 0.3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8  0.8  0.8  0.8 ]\n",
      " [0.1  0.1  0.1  0.1 ]\n",
      " [0.03 0.03 0.03 0.03]\n",
      " [0.05 0.05 0.05 0.05]\n",
      " [0.02 0.02 0.02 0.02]]\n",
      "ar: (5, 4)\n",
      "\n",
      "c: (4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "T, H = 5, 4\n",
    "hs = np.random.randn(T, H)\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "\n",
    "ar = a.reshape(5,1).repeat(4, axis=1) ## repeat를 사용하지 않아도 broadcasting이 일어날 것이지만 눈에 잘 띄지 않음. 역전파도 수행해야 함. repeat에 대한 역전파는 각 미분 계수의 누적합으로 계산됨\n",
    "print(ar)\n",
    "print(f\"ar: {ar.shape}\")\n",
    "print()\n",
    "\n",
    "t = hs * ar\n",
    "\n",
    "c = np.sum(t, axis=0)\n",
    "print(f\"c: {c.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.8  0.8  0.8  0.8 ]\n",
      " [0.1  0.1  0.1  0.1 ]\n",
      " [0.03 0.03 0.03 0.03]\n",
      " [0.05 0.05 0.05 0.05]\n",
      " [0.02 0.02 0.02 0.02]]\n",
      "ar: (5, 4)\n",
      "\n",
      "c: (4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "\n",
    "T, H = 5, 4\n",
    "hs = np.random.randn(T, H)\n",
    "a = np.array([0.8, 0.1, 0.03, 0.05, 0.02])\n",
    "\n",
    "ar = a.reshape(5,1).repeat(4, axis=1) ## repeat를 사용하지 않아도 broadcasting이 일어날 것이지만 눈에 잘 띄지 않음. 역전파도 수행해야 함. repeat에 대한 역전파는 각 미분 계수의 누적합으로 계산됨\n",
    "print(ar)\n",
    "print(f\"ar: {ar.shape}\")\n",
    "print()\n",
    "\n",
    "t = np.matmul(hs, a)\n",
    "\n",
    "\n",
    "c = np.sum(t, axis=0)\n",
    "print(f\"c: {c.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.01.16(화)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def AND(x1, x2):\n",
    "    w1, w2, theta = 0.5, 0.5, 0.7\n",
    "    y = x1*w1 + x2*w2\n",
    "    if y < theta:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "print(AND(1,1))\n",
    "print(AND(1,0))\n",
    "print(AND(0,1))\n",
    "print(AND(0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def OR(x1, x2):\n",
    "    w1, w2, theta = 0.5, 0.5, 0.5\n",
    "    y = x1*w1 + x2*w2\n",
    "    if y < theta:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "print(OR(1,1))\n",
    "print(OR(1,0))\n",
    "print(OR(0,1))\n",
    "print(OR(0,0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "def NAND(x1, x2):\n",
    "    w1, w2, theta = 0.5, 0.5, 0.5\n",
    "    y = x1*w1 + x2*w2\n",
    "    if y > theta:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "print(NAND(1,1))\n",
    "print(NAND(1,0))\n",
    "print(NAND(0,1))\n",
    "print(NAND(0,0))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def XOR(x1, x2):\n",
    "    t1, t2 = NAND(x1, x2), OR(x1, x2)\n",
    "    y = AND(t1, t2)\n",
    "    return y\n",
    "\n",
    "print(XOR(0,0))\n",
    "print(XOR(0,1))\n",
    "print(XOR(1,0))\n",
    "print(XOR(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24.01.07(수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def step_function(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "step_function(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_function(x):\n",
    "    y = x > 0\n",
    "    return y.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0], dtype=int32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_function(np.array([1,-1,-2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
